{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eolearn.core import EOWorkflow, Dependency\n",
    "from eolearn.core import FeatureType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio.features\n",
    "import rasterio.transform\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eolearn.core import LoadFromDisk, SaveToDisk, AddFeature, EOPatch, EOTask, FeatureTypeSet, FeatureType, LinearWorkflow, EOExecutor\n",
    "from eolearn.io import S2L1CWCSInput, AddSen2CorClassificationFeature\n",
    "from eolearn.features import LinearInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markbogataj/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector, AddValidDataMaskTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = -5\n",
    "fraction_size = 0.05 # koliksen del podatkov vzame\n",
    "spatial = False\n",
    "window = 1 # če je 1 je per pixel, drugače pa glede na velikost okna\n",
    "interpolation_range = [8]#2,4,8,16,32,64,128] # [2,4,8] # [16, 32] # [2,4,8,16,32]\n",
    "mask_valid = 'VALID_DATA' # L1C_VALID changed from VALID_DATA\n",
    "#resampled_range = ('2017-01-01', '2017-09-30', interpolation)\n",
    "drop_classes = [1,3,4,5,8,14,16,18,19,21]\n",
    "class_labels = set(list(range(1,26))) - set(drop_classes)\n",
    "MAIN_FOLDER = Path('/Volumes/Seagate_drive') # spremenis na path do podatkov zip-a\n",
    "DATA_FOLDER = os.path.join(MAIN_FOLDER, 'original')\n",
    "DATA_LIST = os.listdir(DATA_FOLDER)\n",
    "#OUTPUT_FOLDER = os.path.join(MAIN_FOLDER, 'interpolation-{}days'.format(interpolation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.05\n"
     ]
    }
   ],
   "source": [
    "actual_fraction = fraction_size/(window*window)\n",
    "print(actual_fraction, actual_fraction*(window**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_patches =[]\n",
    "for name in DATA_LIST:\n",
    "    if(name == '.DS_Store'):\n",
    "        continue\n",
    "    else:\n",
    "        eopatch = EOPatch.load(os.path.join(DATA_FOLDER, name), lazy_loading=True)\n",
    "        if len(eopatch.data)!=0:\n",
    "            non_empty_patches.append(name)\n",
    "DATA_LIST = non_empty_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eopatch_100_col-8_row-7',\n",
       " 'eopatch_101_col-8_row-8',\n",
       " 'eopatch_102_col-8_row-9',\n",
       " 'eopatch_103_col-8_row-10',\n",
       " 'eopatch_107_col-9_row-3',\n",
       " 'eopatch_108_col-9_row-4',\n",
       " 'eopatch_109_col-9_row-5',\n",
       " 'eopatch_10_col-1_row-7',\n",
       " 'eopatch_110_col-9_row-6',\n",
       " 'eopatch_111_col-9_row-7',\n",
       " 'eopatch_112_col-9_row-8',\n",
       " 'eopatch_113_col-9_row-9',\n",
       " 'eopatch_114_col-9_row-10',\n",
       " 'eopatch_119_col-10_row-3',\n",
       " 'eopatch_120_col-10_row-4']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA_LIST= DATA_LIST[:1]\n",
    "print(len(DATA_LIST[:5]))\n",
    "DATA_LIST = DATA_LIST[:15]\n",
    "DATA_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bufferPolys(EOTask):\n",
    "    \n",
    "    def __init__(self, features, buffer):\n",
    "        self.feature_type, self.feature_name = features[0], features[1]\n",
    "        self.buffer = buffer\n",
    "    \n",
    "    def execute(self, eop):\n",
    "        # crops = eopatch.vector_timeless['LPIS_2017']\n",
    "        crops = eop[self.feature_type][self.feature_name]\n",
    "        crops_buffered = crops.copy(deep=True)\n",
    "        # make buffer = -5\n",
    "        crops_buffered.geometry = crops.buffer(self.buffer)\n",
    "        crops_buffered = crops_buffered[~crops_buffered.is_empty]\n",
    "        crops_buffered['SIFRA_KMRS'] = pd.to_numeric(crops_buffered['SIFRA_KMRS'])\n",
    "\n",
    "        eop.add_feature(FeatureType.VECTOR_TIMELESS, 'LPIS_buffered', crops_buffered)\n",
    "        \n",
    "        return eop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorToRasterMultiple(EOTask):\n",
    "    \"\"\"\n",
    "    Task burns into one of the EOPatch's features geo-referenced shapes given in provided Geopandas DataFrame.\n",
    "\n",
    "    :param feature: A tuple of feature type and feature name, e.g. (FeatureType.MASK, 'cloud_mask')\n",
    "    :type feature: (FeatureType, str)\n",
    "    :param vector_data: Vector data\n",
    "    :type vector_data: geopandas.GeoDataFrame\n",
    "    :param raster_value: Value of raster pixels which are contained inside of vector polygons\n",
    "    :type raster_value: int or float\n",
    "    :param raster_shape: Can be a tuple in form of (height, width) of an existing feature from which the shape will be\n",
    "                            taken e.g. (FeatureType.MASK, 'IS_DATA')\n",
    "    :type raster_shape: (int, int) or (FeatureType, str)\n",
    "    :param raster_dtype: `numpy` data type of the obtained raster array\n",
    "    :type raster_dtype: numpy.dtype\n",
    "    :param no_data_value: Value of raster pixels which are outside of vector polygons\n",
    "    :type no_data_value: int or float\n",
    "    :param kwargs: arguments passed to rasterio.features.rasterize\n",
    "    \"\"\"\n",
    "    def __init__(self, feature, vector_feature, raster_value, raster_shape, raster_dtype=np.uint8, no_data_value=0,\n",
    "                 **kwargs):\n",
    "        self.feature_type, self.feature_name = next(iter(self._parse_features(feature)))\n",
    "        self.vector_feature = vector_feature\n",
    "        self.raster_value = raster_value\n",
    "        self.raster_shape = raster_shape\n",
    "        self.raster_dtype = raster_dtype\n",
    "        self.no_data_value = no_data_value\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def _get_submap(self, eopatch):\n",
    "        \"\"\"\n",
    "        Returns a new geopandas dataframe with same structure as original one (columns) except that\n",
    "        it contains only polygons that are contained within the given bbox.\n",
    "\n",
    "        :param eopatch: input EOPatch\n",
    "        :type eopatch: EOPatch\n",
    "        :return: New EOPatch\n",
    "        :rtype: EOPatch\n",
    "        \"\"\"\n",
    "#         bbox_poly = eopatch.bbox.get_geometry()\n",
    "        bbox_poly = eopatch.bbox.geometry\n",
    "        vector_data = eopatch[self.vector_feature[0]][self.vector_feature[1]]\n",
    "        \n",
    "        vector_data = vector_data[vector_data.geometry.intersects(bbox_poly)].copy(deep=True)\n",
    "        \n",
    "        vector_data.geometry = vector_data.geometry.buffer(0)\n",
    "        vetor_data = vector_data[vector_data.geometry.is_valid]\n",
    "        vetor_data = vector_data[~vector_data.geometry.is_empty]\n",
    "        \n",
    "        filtered_data = vector_data[vector_data.geometry.intersects(bbox_poly)].copy(deep=True)\n",
    "        pairs = []\n",
    "        for idx, row in filtered_data.iterrows():\n",
    "            pairs.append((row.geometry, row[self.raster_value]))\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "        \"\"\" Execute function which adds new vector layer to the EOPatch\n",
    "\n",
    "        :param eopatch: input EOPatch\n",
    "        :type eopatch: EOPatch\n",
    "        :return: New EOPatch with added vector layer\n",
    "        :rtype: EOPatch\n",
    "        \"\"\"\n",
    "        # print(eopatch)\n",
    "        bbox_map = self._get_submap(eopatch)\n",
    "        height = eopatch[FeatureType.MASK]['IS_DATA'].shape[1] * 10\n",
    "        width = eopatch[FeatureType.MASK]['IS_DATA'].shape[2] * 10\n",
    "        \n",
    "        data_transform = rasterio.transform.from_bounds(*eopatch.bbox, width=width, height=height)\n",
    "\n",
    "        if self.feature_name in eopatch[self.feature_type]:\n",
    "            raster = eopatch[self.feature_type][self.feature_name].squeeze()\n",
    "        else:\n",
    "            raster = np.ones((height, width), dtype=self.raster_dtype) * self.no_data_value\n",
    "\n",
    "        if len(bbox_map):\n",
    "            rasterio.features.rasterize(bbox_map, out=raster,\n",
    "                                        transform=data_transform,\n",
    "                                        dtype=self.raster_dtype,\n",
    "                                        **self.kwargs)\n",
    "\n",
    "        eopatch[self.feature_type][self.feature_name] = raster[..., np.newaxis]\n",
    "\n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class select_bands(EOTask):\n",
    "    \n",
    "    def __init__(self, feature, new_feature_name, features):\n",
    "        self.feature_type, self.feature_name = feature[0], feature[1]\n",
    "        self.new_feature_name = new_feature_name\n",
    "        self.features = features\n",
    "    \n",
    "    def execute(self, eop):\n",
    "        bands = eop[self.feature_type][self.feature_name]\n",
    "        bands_new = bands[:, :, :, self.features]\n",
    "        eop.add_feature(self.feature_type, self.new_feature_name, bands_new)\n",
    "        \n",
    "        return eop\n",
    "    \n",
    "class NormalizedDifferenceIndex(EOTask):   \n",
    "    \"\"\"\n",
    "    The tasks calculates user defined Normalised Difference Index (NDI) between two bands A and B as:\n",
    "    NDI = (A-B)/(A+B).\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_name, band_a, band_b):\n",
    "        self.feature_name = feature_name\n",
    "        self.band_a_fetaure_name = band_a.split('/')[0]\n",
    "        self.band_b_fetaure_name = band_b.split('/')[0]\n",
    "        self.band_a_fetaure_idx = int(band_a.split('/')[-1])\n",
    "        self.band_b_fetaure_idx = int(band_b.split('/')[-1])\n",
    "        \n",
    "    def execute(self, eopatch):\n",
    "        band_a = eopatch.data[self.band_a_fetaure_name][..., self.band_a_fetaure_idx]\n",
    "        band_b = eopatch.data[self.band_b_fetaure_name][..., self.band_b_fetaure_idx]\n",
    "        \n",
    "        ndi = (band_a - band_b) / (band_a  + band_b)\n",
    "        \n",
    "        eopatch.add_feature(FeatureType.DATA, self.feature_name, ndi[..., np.newaxis])\n",
    "        \n",
    "        return eopatch\n",
    "    \n",
    "class EuclideanNorm(EOTask):   \n",
    "    \"\"\"\n",
    "    The tasks calculates Euclidian Norm of all bands within an array:\n",
    "    norm = sqrt(sum_i Bi**2),\n",
    "    where Bi are the individual bands within user-specified feature array.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_name, in_feature_name):\n",
    "        self.feature_name = feature_name\n",
    "        self.in_feature_name = in_feature_name\n",
    "    \n",
    "    def execute(self, eopatch):\n",
    "        arr = eopatch.data[self.in_feature_name]\n",
    "        norm = np.sqrt(np.sum(arr**2, axis=-1))\n",
    "        \n",
    "        eopatch.add_feature(FeatureType.DATA, self.feature_name, norm[..., np.newaxis])\n",
    "        return eopatch\n",
    "\n",
    "class ConcatenateData(EOTask):\n",
    "    \"\"\" Task to concatenate data arrays along the last dimension\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_name, feature_names_to_concatenate):\n",
    "        self.feature_name = feature_name\n",
    "        self.feature_names_to_concatenate = feature_names_to_concatenate\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "        arrays = [eopatch.data[name] for name in self.feature_names_to_concatenate]\n",
    "\n",
    "        eopatch.add_feature(FeatureType.DATA, self.feature_name, np.concatenate(arrays, axis=-1))\n",
    "\n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampleMajority(mask, rows, cols, fraction):\n",
    "    sampled = np.random.rand(len(rows)) > (1.0 - fraction*2) # increase sample size by 2 to later reduce by 50%\n",
    "    \n",
    "    sampled_classes = mask[rows[sampled], cols[sampled]]\n",
    "    # checking the distribution of mapped classes\n",
    "    sampled_classes = np.array([get_numeric_group(get_group_id(str(x).zfill(3), lpis_to_group), group_to_numeric) for x in sampled_classes])\n",
    "    values = np.unique(sampled_classes, return_counts=True)\n",
    "    number_of_2 = values[1][np.where(values[0]==2)[0]][0]\n",
    "    \n",
    "    for location, x in enumerate(sampled_classes):\n",
    "        if x in drop_classes:\n",
    "            sampled_classes[location] = 0\n",
    "            \n",
    "    clean = sampled_classes==0\n",
    "    sampled_classes = sampled_classes[~clean]\n",
    "    \n",
    "    sampled2 = np.random.rand(number_of_2) > (1.0 - 1/6) # we want only 1/6 of them all\n",
    "        \n",
    "    sub_sample = np.where(sampled_classes==2)[0][~sampled2]\n",
    "    sampled[np.where(sampled==True)[0][sub_sample]]=False\n",
    "    \n",
    "    #sampled_classes = mask[rows[sampled], cols[sampled]]\n",
    "    #sampled_classes = np.array([get_numeric_group(get_group_id(str(x).zfill(3), lpis_to_group), group_to_numeric) for x in sampled_classes])\n",
    "    #values = np.unique(sampled_classes, return_counts=True)\n",
    "    #distrib = np.round(values[1]/sum(values[1]), 6)\n",
    "    #fig = plt.figure(figsize=(15, 15))\n",
    "    #plt.bar(values[0], distrib, align='center')\n",
    "    #plt.xticks(values[0], values[0]);\n",
    "    \n",
    "    return sampled\n",
    "\n",
    "def sample(mask, rows, cols, fraction):\n",
    "    sampled = np.random.rand(len(rows)) > (1.0 - fraction)\n",
    "    return sampled\n",
    "\n",
    "class SampleValid(EOTask):\n",
    "    \"\"\"\n",
    "    The task samples pixels with a value in given timeless feature different from no valid data value.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature, fraction=1.0, no_data_value=0, sample_features=...):\n",
    "        \"\"\" Task to sample pixels from a reference timeless raster mask, excluding a no valid data value\n",
    "\n",
    "        :param feature:  Reference feature used to select points to be sampled\n",
    "        :param fraction: Fraction of valid points to be sampled\n",
    "        :param no_data_value: Value of non-valid points to be ignored\n",
    "        \"\"\"\n",
    "        self.feature_type, self.feature_name, self.new_feature_name = next(\n",
    "            self._parse_features(feature, new_names=True,\n",
    "                                 default_feature_type=FeatureType.MASK_TIMELESS,\n",
    "                                 allowed_feature_types={FeatureType.MASK_TIMELESS},\n",
    "                                 rename_function='{}_SAMPLED'.format)())\n",
    "        self.fraction = fraction\n",
    "        self.no_data_value = no_data_value\n",
    "        self.sample_features = self._parse_features(sample_features)\n",
    "\n",
    "    def execute(self, in_eopatch, eopatch_folder, OUTPUT_FOLDER, seed=None):\n",
    "        eopatch = in_eopatch.__copy__()\n",
    "        #print(eopatch_folder)\n",
    "        mask = eopatch[self.feature_type][self.feature_name].squeeze()\n",
    "\n",
    "        if mask.ndim != 2:\n",
    "            raise ValueError('Invalid shape of sampling reference map.')\n",
    "        \n",
    "        rows, cols = np.where(mask != self.no_data_value)\n",
    "        sampling_file = Path(os.path.join(OUTPUT_FOLDER, eopatch_folder, 'sampling.npy'))\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        if not os.path.exists(os.path.join(OUTPUT_FOLDER, eopatch_folder)):\n",
    "            os.makedirs(os.path.join(OUTPUT_FOLDER, eopatch_folder))\n",
    "            \n",
    "        if sampling_file.is_file():\n",
    "            sampled = np.load(sampling_file)\n",
    "            if not(round(np.sum(sampled)/len(rows), 2) == self.fraction):\n",
    "                print(\"fraction mismatch\")\n",
    "                #sampled = undersampleMajority(mask, rows, cols, self.fraction)\n",
    "                sampled = sample(mask, rows, cols, self.fraction)\n",
    "                np.save(sampling_file, sampled)\n",
    "            \n",
    "        else:\n",
    "            #sampled = undersampleMajority(mask, rows, cols, self.fraction)            \n",
    "            sampled = sample(mask, rows, cols, self.fraction) \n",
    "            print(\"saving new fraction, file didn't exist\")\n",
    "            np.save(sampling_file, sampled)\n",
    "            \n",
    "        rows = rows[sampled]\n",
    "        cols = cols[sampled]\n",
    "\n",
    "        for feature_type, feature_name in self.sample_features(eopatch):\n",
    "\n",
    "            if feature_type in FeatureTypeSet.RASTER_TYPES.intersection(FeatureTypeSet.SPATIAL_TYPES):\n",
    "\n",
    "                if feature_type.is_time_dependent():\n",
    "                    sampled_data = eopatch[feature_type][feature_name][:, rows, cols, :]\n",
    "                else:\n",
    "                    sampled_data = eopatch[feature_type][feature_name][rows, cols, :]\n",
    "\n",
    "                # here a copy of sampled array is returned and assigned to feature of a shallow copy\n",
    "                # orig_eopatch[feature_type][feature_name] remains unmodified\n",
    "                eopatch[feature_type][feature_name] = sampled_data[..., np.newaxis, :]\n",
    "\n",
    "        new_mask = np.ones_like(mask)*self.no_data_value\n",
    "        new_mask[rows, cols] = mask[rows, cols]        \n",
    "        eopatch[self.feature_type][self.new_feature_name] = new_mask[..., np.newaxis]\n",
    "        eopatch[FeatureType.SCALAR_TIMELESS]['SAMPLED_ROWS'] = rows\n",
    "        eopatch[FeatureType.SCALAR_TIMELESS]['SAMPLED_COLS'] = cols\n",
    "\n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleValidSpatial(EOTask):\n",
    "    \"\"\"\n",
    "    The task samples pixels with a value in given timeless feature different from no valid data value.\n",
    "    \"\"\"\n",
    "\n",
    "    #def __init__(self, feature, fraction=1.0, window=24, no_data_value=0, increase=1, sample_features=...):\n",
    "    def __init__(self, feature, fraction=1.0, window=1, no_data_value=0, increase=1, sample_features=...):\n",
    "        \"\"\" Task to sample pixels from a reference timeless raster mask, excluding a no valid data value\n",
    "\n",
    "        :param feature:  Reference feature used to select points to be sampled\n",
    "        :param fraction: Fraction of valid points to be sampled\n",
    "        :param no_data_value: Value of non-valid points to be ignored\n",
    "        \"\"\"\n",
    "        self.feature_type, self.feature_name, self.new_feature_name = next(\n",
    "            self._parse_features(feature, new_names=True,\n",
    "                                 default_feature_type=FeatureType.MASK_TIMELESS,\n",
    "                                 allowed_feature_types={FeatureType.MASK_TIMELESS},\n",
    "                                 rename_function='{}_SAMPLED'.format)())\n",
    "        self.fraction = fraction\n",
    "        self.no_data_value = no_data_value\n",
    "        self.sample_features = self._parse_features(sample_features)\n",
    "        self.window = window\n",
    "        self.increase = increase\n",
    "\n",
    "    def sample_spatial(self, mask, rows, cols, fraction):\n",
    "\n",
    "        # double the amount of sampled data to be reduced based on coverage\n",
    "        sampled = np.random.rand(len(rows)) > (1.0 - self.fraction*self.increase)\n",
    "        #print(\"sampled\", np.sum(sampled), \"which is\", np.sum(sampled)/len(rows))\n",
    "        # TODO save sampling        \n",
    "        rows = rows[sampled]\n",
    "        cols = cols[sampled]\n",
    "\n",
    "        new_mask = np.array([mask[(x-self.window//2):(x+ceil(self.window/2)), (y-self.window//2):(y+ceil(self.window/2))] for x,y in zip(rows,cols)])\n",
    "        no_data_part = []        \n",
    "        # to increase and reduce data where there is data\n",
    "        if self.increase != 1:\n",
    "            for x in new_mask:\n",
    "                uniq = np.unique(x, return_counts=True)\n",
    "                if self.no_data_value in uniq[0]:\n",
    "                    number_of_0 = uniq[1][np.where(uniq[0]==self.no_data_value)[0]][0]\n",
    "                    no_data_part.append(number_of_0/np.sum(uniq[1]))\n",
    "                else: # in case all samples have label different from no_data_value\n",
    "                    no_data_part.append(0)\n",
    "\n",
    "            ordered = np.array(sorted(enumerate(no_data_part), key=lambda x:x[1]))\n",
    "            to_keep = np.array(ordered[:(len(ordered)//self.increase),0], dtype= np.int16)\n",
    "            #print(len(to_keep))\n",
    "            new_mask = new_mask[to_keep]\n",
    "            rows = rows[to_keep]\n",
    "            cols = cols[to_keep]\n",
    "            \n",
    "            # testing distribution\n",
    "            #print(np.unique(np.round(np.array(no_data_part)[to_keep],1), return_counts=True))\n",
    "            # print(np.unique(np.round(no_data_part,1), return_counts=True))\n",
    "            # fit = stats.norm.pdf(ordered[:,1], np.mean(ordered[:,1]), np.std(ordered[:,1]))\n",
    "            # plt.plot(ordered[:,1], fit, '-')\n",
    "            # plt.hist(ordered[:,1], normed=True)\n",
    "            # plt.savefig(\"dist1.png\")\n",
    "            # #print(ordered.shape)\n",
    "            # #print(ordered)\n",
    "\n",
    "            #-----------testing distribution of no data\n",
    "            # no_data_part = []\n",
    "            # n_pixels=0\n",
    "            # for x in new_mask:\n",
    "            #     uniq = np.unique(x, return_counts=True)\n",
    "            #     if self.no_data_value in uniq[0]:\n",
    "            #         number_of_0 = uniq[1][np.where(uniq[0]==self.no_data_value)[0]][0]\n",
    "            #         no_data_part.append(number_of_0/np.sum(uniq[1]))\n",
    "            #     else: # in case all samples have label different from no_data_value\n",
    "            #         no_data_part.append(0)\n",
    "\n",
    "            # ordered = np.array(sorted(enumerate(no_data_part), key=lambda x:x[1]))\n",
    "\n",
    "            # print(np.unique(np.round(no_data_part,1), return_counts=True))\n",
    "            # fit = stats.norm.pdf(no_data_part, np.mean(no_data_part), np.std(no_data_part))\n",
    "            # plt.plot(no_data_part, fit, '-')\n",
    "            # plt.hist(no_data_part, normed=True)\n",
    "            # plt.savefig(\"dist2.png\")\n",
    "            #print(len(ordered))\n",
    "            #print(ordered)\n",
    "        \n",
    "        return rows, cols\n",
    "       \n",
    "        \n",
    "    \n",
    "    def execute(self, in_eopatch, eopatch_folder, OUTPUT_FOLDER, seed=None):\n",
    "        eopatch = in_eopatch.__copy__()\n",
    "        \n",
    "      \n",
    "\n",
    "        \n",
    "        # new_mask = np.array([mask[(x-self.window//2):(x+ceil(self.window/2)), (y-self.window//2):(y+ceil(self.window/2))] for x,y in zip(rows,cols)])\n",
    "        #print(mask.shape)\n",
    "        #print(new_mask.shape)\n",
    "        # reducing data based on no_data_label\n",
    "        \n",
    "        # no_data_part = []        \n",
    "        # to increase and reduce data where there is data\n",
    "        # if increase != 1:\n",
    "        #     for x in new_mask:\n",
    "        #         uniq = np.unique(x, return_counts=True)\n",
    "        #         if self.no_data_value in uniq[0]:\n",
    "        #             number_of_0 = uniq[1][np.where(uniq[0]==self.no_data_value)[0]][0]\n",
    "        #             no_data_part.append(number_of_0/np.sum(uniq[1]))\n",
    "        #         else: # in case all samples have label different from no_data_value\n",
    "        #             no_data_part.append(0)\n",
    "        #         \n",
    "        #     ordered = np.array(sorted(enumerate(no_data_part), key=lambda x:x[1]))\n",
    "        #     to_keep = np.array(ordered[:(len(ordered)//increase),0], dtype= np.int16)\n",
    "        #     #print(len(to_keep))\n",
    "        #     new_mask = new_mask[to_keep]\n",
    "        #     rows = rows[to_keep]\n",
    "        #     cols = cols[to_keep]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-----------testing distribution of no data\n",
    "        #no_data_part = []\n",
    "        #n_pixels=0\n",
    "        #for x in new_mask:\n",
    "        #    uniq = np.unique(x, return_counts=True)\n",
    "        #    number_of_0 = uniq[1][np.where(uniq[0]==self.no_data_value)[0]][0]\n",
    "        #    no_data_part.append(number_of_0/np.sum(uniq[1]))\n",
    "        #    n_pixels += np.sum(uniq[1])\n",
    "        #    #print(uniq)\n",
    "        ##print(n_pixels)\n",
    "        #ordered = sorted(no_data_part)\n",
    "        #fit = stats.norm.pdf(ordered, np.mean(ordered), np.std(ordered))\n",
    "        #plt.plot(ordered, fit, '-')\n",
    "        #plt.hist(ordered, normed=True)\n",
    "        #plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "         # ------------------from sampling valid\n",
    "        mask = eopatch[self.feature_type][self.feature_name].squeeze()\n",
    "        h, w = mask.shape\n",
    "        if mask.ndim != 2:\n",
    "            raise ValueError('Invalid shape of sampling reference map.')\n",
    "\n",
    "        np.random.seed(int(eopatch_folder.split('_')[1]))\n",
    "        increase = 1\n",
    "        rows1, cols1 = np.where(mask != self.no_data_value)\n",
    "        # moving towards the inside of the patch so patch is defined in sampled area\n",
    "        clean = np.logical_and(rows1>=self.window//2, rows1<=(h-ceil(self.window/2)))\n",
    "        # #print(\"bounds x\", len(rows)-np.sum(clean))\n",
    "        rows1 = rows1[clean]\n",
    "        cols1 = cols1[clean]\n",
    "        clean = np.logical_and(cols1>=self.window//2, cols1<=(w-ceil(self.window/2)))\n",
    "        #print(\"bounds y\", len(cols)-np.sum(clean))\n",
    "        rows1 = rows1[clean]\n",
    "        cols1 = cols1[clean]\n",
    "        \n",
    "\n",
    "               \n",
    "        sampling_file = Path(os.path.join(OUTPUT_FOLDER, eopatch_folder+'sampling.npy'))\n",
    "        np.random.seed(seed)\n",
    "        if not os.path.exists(OUTPUT_FOLDER):\n",
    "            os.makedirs(OUTPUT_FOLDER)\n",
    "            \n",
    "        if sampling_file.is_file(): # not loading fraction beacause just one interpolation sampling_file.is_file():\n",
    "            rows, cols = np.load(sampling_file, allow_pickle=True)\n",
    "            if not(round(len(rows)/len(rows1), 3) == self.fraction):\n",
    "                print(\"fraction mismatch\", round(len(rows)/len(rows1), 3), self.fraction)\n",
    "                #rows, cols = self.sample_spatial(mask, rows1, cols1, self.fraction)\n",
    "                #np.save(sampling_file, (rows, cols))\n",
    "            \n",
    "        else:\n",
    "            rows, cols = self.sample_spatial(mask, rows1, cols1, self.fraction) \n",
    "            print(\"saving new fraction, file didn't exist\")\n",
    "            np.save(sampling_file, (rows, cols))\n",
    "            \n",
    "        #rows = rows[sampled]\n",
    "        #cols = cols[sampled] #empty\n",
    "        \n",
    "        for feature_type, feature_name in self.sample_features(eopatch):\n",
    "            if feature_type in FeatureTypeSet.RASTER_TYPES.intersection(FeatureTypeSet.SPATIAL_TYPES):\n",
    "                if feature_type.is_time_dependent():\n",
    "                    sampled_data = np.array([eopatch[feature_type][feature_name][:,(x-self.window//2):(x+ceil(self.window/2)), (y-self.window//2):(y+ceil(self.window/2)), :] for x,y in zip(rows,cols)])\n",
    "                    sampled_data = np.transpose(sampled_data, (1, 0, 2, 3, 4))\n",
    "                    t,s,wi,he,b = sampled_data.shape\n",
    "                    sampled_data = sampled_data.reshape(t,s,wi*he,b)\n",
    "                else:\n",
    "                    sampled_data = np.array([eopatch[feature_type][feature_name][(x-self.window//2):(x+ceil(self.window/2)), (y-self.window//2):(y+ceil(self.window/2)), :] for x,y in zip(rows,cols)])\n",
    "                    s,wi,he,b = sampled_data.shape\n",
    "                    sampled_data = sampled_data.reshape(s,wi*he,b)\n",
    "        \n",
    "                eopatch[feature_type][feature_name] = sampled_data\n",
    "        \n",
    "        #print(list(zip(rows, cols))[:10])\n",
    "        #print(mask[rows[:10], cols[:10]])\n",
    "        new_mask = np.ones_like(mask)*self.no_data_value\n",
    "        new_mask[rows, cols] = mask[rows, cols]\n",
    "        eopatch[self.feature_type][self.new_feature_name] = new_mask[..., np.newaxis]\n",
    "        eopatch[FeatureType.SCALAR_TIMELESS]['SAMPLED_ROWS'] = rows\n",
    "        eopatch[FeatureType.SCALAR_TIMELESS]['SAMPLED_COLS'] = cols\n",
    "\n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_id(crop_group, crop_group_df, group_name='CROP_ID',\n",
    "             group_id='GROUP_1', default_value=0):\n",
    "    \"\"\"\n",
    "    Returns numeric crop group value for specified crop group name. The mapping is obtained from\n",
    "    the specified crop group pandas DataFrame.\n",
    "    \"\"\"\n",
    "    values = crop_group_df[crop_group_df[group_name]==crop_group][group_id].values\n",
    "    if len(values)==0:\n",
    "        return default_value\n",
    "    else:\n",
    "        return values[-1]\n",
    "\n",
    "def get_numeric_group(crop_group, crop_group_df, group_name='GROUP_1_NAME',\n",
    "                 group_id='GROUP_1_ID', default_value=0):\n",
    "    \"\"\"\n",
    "    Returns numeric crop group value for specified crop group name. The mapping is obtained from\n",
    "    the specified crop group pandas DataFrame.\n",
    "    \"\"\"\n",
    "    values = crop_group_df[crop_group_df[group_name]==crop_group][group_id].values\n",
    "    if len(values)==0:\n",
    "        return default_value\n",
    "    else:\n",
    "        return values[-1]\n",
    "\n",
    "class group_crops_spatial(EOTask):\n",
    "    def __init__(self, lpis_to_group, group_to_numeric):\n",
    "        self.lpis_to_group = lpis_to_group\n",
    "        self.group_to_numeric = group_to_numeric\n",
    "    \n",
    "    def execute(self, eop):\n",
    "        arr = []\n",
    "        if eop.mask_timeless['LPIS_sifra'].shape[1] == 1:\n",
    "               arr = [[get_numeric_group(get_group_id(str(y).zfill(3), self.lpis_to_group), self.group_to_numeric)] for y in eop.mask_timeless['LPIS_sifra'].squeeze()]\n",
    "        else: \n",
    "            for y in eop.mask_timeless['LPIS_sifra'].squeeze():\n",
    "                arr.append([get_numeric_group(get_group_id(str(x).zfill(3), self.lpis_to_group), self.group_to_numeric) for x in y])\n",
    "                    #print(np.unique(arr[-1], return_counts=True))\n",
    "                #break\n",
    "        #print(eop.mask_timeless['LPIS_sifra'].squeeze()[np.where(np.array(arr) == 23)])\n",
    "        arr = np.array(arr)\n",
    "        #aar shape[1] is 1 when no spatial data is included\n",
    "        eop.mask_timeless['LPIS_sifra'] = arr[...,np.newaxis]\n",
    "        #print(np.unique(arr, return_counts=True))\n",
    "        return eop\n",
    "    \n",
    "class group_crops(EOTask):\n",
    "    def __init__(self, lpis_to_group, group_to_numeric):\n",
    "        self.lpis_to_group = lpis_to_group\n",
    "        self.group_to_numeric = group_to_numeric\n",
    "    \n",
    "    def execute(self, eop):\n",
    "        # print(np.unique(eop.mask_timeless['LPIS_sifra'], return_counts=True))\n",
    "        groups = list(get_group_id(str(x).zfill(3), self.lpis_to_group) for x in eop.mask_timeless['LPIS_sifra'].squeeze())\n",
    "        # print(np.unique(groups, return_counts=True))\n",
    "        tt = np.array([get_numeric_group(x, self.group_to_numeric) for x in groups])\n",
    "             # np.array(list(get_numeric_group(get_group_id(str(x).zfill(3), lpis_to_group), group_to_numeric) for x in sampled.mask_timeless['LPIS_sifra']))\n",
    "        # print(np.unique(tt, return_counts=True))\n",
    "        eop.mask_timeless['LPIS_sifra'] = tt.reshape([len(tt),1,1])\n",
    "        # eop.data['BANDS-S2-L2A'] = np.squeeze(eop.data['BANDS-S2-L2A'], axis=2)\n",
    "        # eop.mask_timeless['PID'] = np.squeeze(eop.mask_timeless['PID'])\n",
    "        return eop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markbogataj/.local/lib/python3.6/site-packages/eolearn/core/core_tasks.py:166: DeprecationWarning: This task is deprecated, use LoadTask instead\n",
      "  warnings.warn('This task is deprecated, use LoadTask instead', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "buffer_poly = bufferPolys((FeatureType.VECTOR_TIMELESS, 'LPIS_2017_org'), buffer)\n",
    "\n",
    "load = LoadFromDisk(folder=DATA_FOLDER, lazy_loading=True)\n",
    "\n",
    "\n",
    "# vec_to_ras_lpis = VectorToRasterMultiple((FeatureType.MASK_TIMELESS, 'LPIS_sifra'),\n",
    "#                                     (FeatureType.VECTOR_TIMELESS, 'LPIS_buffered'),\n",
    "#                                     'SIFRA_KMRS', raster_shape=(FeatureType.MASK, 'IS_DATA'),\n",
    "#                                     raster_dtype=np.uint16, no_data_value=0)\n",
    "\n",
    "# vec_to_ras_pid = VectorToRasterMultiple((FeatureType.MASK_TIMELESS, 'PID'),\n",
    "#                                     (FeatureType.VECTOR_TIMELESS, 'LPIS_buffered'),\n",
    "#                                     'GERK_PID', raster_shape=(FeatureType.MASK, 'IS_DATA'),\n",
    "#                                     raster_dtype=np.uint32, no_data_value=0)\n",
    "\n",
    "vec_to_multi_raster = VectorToRasterMultiple((FeatureType.MASK_TIMELESS, 'LPIS_MULTI'),\n",
    "                                    (FeatureType.VECTOR_TIMELESS, 'LPIS_buffered'),\n",
    "                                    'SIFRA_KMRS', raster_shape=(FeatureType.MASK, 'IS_DATA'),\n",
    "                                    raster_dtype=np.uint32, no_data_value=0)\n",
    "\n",
    "\n",
    "# [(FeatureType.DATA, 'BANDS-S2-L2A'), (FeatureType.MASK, mask_valid), FeatureType.MASK_TIMELESS])\n",
    "sampling = SampleValidSpatial((FeatureType.MASK_TIMELESS, 'LPIS_sifra'),\n",
    "                       fraction=actual_fraction, no_data_value=0,\n",
    "                                window=window, increase=2,\n",
    "                       sample_features=[(FeatureType.DATA, 'BANDS-S2-L2A'),\n",
    "                                        (FeatureType.MASK, mask_valid),\n",
    "                                        FeatureType.MASK_TIMELESS])\n",
    "\n",
    "#B(B02), G(B03), R(B04), NIR (B08)\n",
    "custom_bands = [2, 3, 4, 8]\n",
    "select = select_bands((FeatureType.DATA, 'BANDS-S2-L2A'), 'BANDS', custom_bands)\n",
    "\n",
    "# TASKS FOR CALCULATING NEW FEATURES\n",
    "# NDVI: (B08 - B04)/(B08 + B04)\n",
    "# NDWI: (B03 - B08)/(B03 + B08)\n",
    "# NORM: sqrt(B02^2 + B03^2 + B04^2 + B08^2 + B11^2 + B12^2)\n",
    "ndvi = NormalizedDifferenceIndex('NDVI', 'BANDS/3', 'BANDS/2')\n",
    "ndwi = NormalizedDifferenceIndex('NDWI', 'BANDS/1', 'BANDS/3')\n",
    "norm = EuclideanNorm('NORM','BANDS')\n",
    "\n",
    "concatenate = ConcatenateData('FEATURES', ['BANDS', 'NDVI', 'NDWI', 'NORM'])\n",
    "\n",
    "lpis_to_group = pd.read_csv(os.path.join(MAIN_FOLDER,\"crop-definitions/slo_lpis_crop_to_group_mapping_20190517.csv\"))\n",
    "group_to_numeric = pd.read_csv(os.path.join(MAIN_FOLDER,\"crop-definitions/crop_group_1_definition_20190517.csv\"))\n",
    "grouping = group_crops_spatial(lpis_to_group, group_to_numeric)\n",
    "\n",
    "#if spatial:\n",
    "#    sampling = SampleValidSpatial((FeatureType.MASK_TIMELESS, 'LPIS_sifra'),\n",
    "#                                 fraction=fraction_size, no_data_value=0, window=window,\n",
    "#                                  sample_features=[(FeatureType.DATA, 'BANDS-S2-L2A'),\n",
    "#                                                   (FeatureType.MASK, mask_valid), FeatureType.MASK_TIMELESS])\n",
    "#    # TODO test group_crops(lpis_to_group, group_to_numeric)\n",
    "#    grouping = group_crops_spatial(lpis_to_group, group_to_numeric)\n",
    "#\n",
    "#else:\n",
    "#    sampling = SampleValid((FeatureType.MASK_TIMELESS, 'LPIS_sifra'),\n",
    "#                                 fraction=fraction_size, no_data_value=0, sample_features=[(FeatureType.DATA, 'BANDS-S2-L2A'), (FeatureType.MASK, mask_valid), FeatureType.MASK_TIMELESS])\n",
    "#    grouping = group_crops(lpis_to_group, group_to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for different interpolations\n",
    "print(str(window) +'_' + str(int(actual_fraction*(window**2)*100)).zfill(2))\n",
    "for interpolation in interpolation_range[::-1]:\n",
    "    resampled_range = ('2017-01-01', '2017-09-30', interpolation)\n",
    "#     OUTPUT_FOLDER = os.path.join(\"/Volumes/Seagate_drive\", 'aFractionIndices{}'.format(str(window)+'_'+str(int(actual_fraction*(window**2)*100)).zfill(2)),  'interpolation-{}days'.format(interpolation))\n",
    "    OUTPUT_FOLDER = os.path.join(\"./\", 'aFractionIndices{}'.format(str(window)+'_'+str(int(actual_fraction*(window**2)*100)).zfill(2)),  'interpolation-{}days'.format(interpolation))\n",
    "    \n",
    "    # workflow\n",
    "    linear_interp = LinearInterpolation(\n",
    "        (FeatureType.DATA,'FEATURES'), # 'BANDS-S2-L2A'\n",
    "        mask_feature=(FeatureType.MASK, mask_valid), # mask to be used in interpolation TODO change from VALID_DATA\n",
    "        copy_features=[(FeatureType.MASK_TIMELESS, 'LPIS_sifra'), (FeatureType.MASK_TIMELESS, 'PID'), (FeatureType.MASK_TIMELESS, 'LPIS_MULTI')], # features to keep\n",
    "        resample_range=resampled_range, # set the resampling range\n",
    "        bounds_error=False # extrapolate with NaN's\n",
    "    )\n",
    "\n",
    "    save = SaveToDisk(OUTPUT_FOLDER, overwrite_permission = 1)\n",
    "    exec_params = []\n",
    "    for name in DATA_LIST:  # [filename for filename in DATA_LIST if 'col-21_row-20' in filename]:\n",
    "        #name = filename.rsplit('/', 1)[1]\n",
    "        exec_params.append({\n",
    "            load: dict(eopatch_folder=name),\n",
    "            save: dict(eopatch_folder=name),\n",
    "            sampling: dict(eopatch_folder=name, OUTPUT_FOLDER=OUTPUT_FOLDER)\n",
    "        })\n",
    "    \n",
    "    workflow = LinearWorkflow(load, buffer_poly, vec_to_ras_lpis, vec_to_ras_pid, vec_to_multi_raster, sampling, select, ndvi, ndwi, norm, concatenate, linear_interp, grouping, save)\n",
    "    executor = EOExecutor(workflow, exec_params, save_logs=True)\n",
    "    print(\"Working on\", interpolation, \"days,\", \"saving to\", OUTPUT_FOLDER)\n",
    "    executor.run(workers=1)\n",
    "#     workflow.execute(exec_params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.make_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data: {\n",
       "    FEATURES: numpy.ndarray(shape=(34, 10721, 1, 7), dtype=float64)\n",
       "  }\n",
       "  mask: {}\n",
       "  scalar: {}\n",
       "  label: {}\n",
       "  vector: {}\n",
       "  data_timeless: {}\n",
       "  mask_timeless: {\n",
       "    LPIS_MULTI: numpy.ndarray(shape=(10721, 1, 1), dtype=uint32)\n",
       "    LPIS_sifra: numpy.ndarray(shape=(10721, 1, 1), dtype=int64)\n",
       "    PID: numpy.ndarray(shape=(10721, 1, 1), dtype=uint32)\n",
       "  }\n",
       "  scalar_timeless: {}\n",
       "  label_timeless: {}\n",
       "  vector_timeless: {}\n",
       "  meta_info: {}\n",
       "  bbox: BBox(((451581.91665190033, 5105816.813818144), (461269.3104915918, 5115262.978997778)), crs=CRS('32633'))\n",
       "  timestamp: [datetime.datetime(2017, 1, 1, 0, 0), ..., datetime.datetime(2017, 9, 22, 0, 0)], length=34\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eopatch = EOPatch.load(os.path.join('./aFractionIndices1_05/interpolation-8days', DATA_LIST[1]))\n",
    "eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_arr = eopatch.data['FEATURES'].copy()\n",
    "lpis_data_arr = eopatch.mask_timeless['LPIS_sifra'].copy()\n",
    "pid_data_arr = eopatch.mask_timeless['PID'].copy()\n",
    "print(features_arr.shape)\n",
    "print(lpis_data_arr.shape)\n",
    "print(pid_data_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cells = []\n",
    "list_of_groundtruth = []\n",
    "\n",
    "list_of_all_LPIS_data = []\n",
    "\n",
    "for idx in range(0, len(DATA_LIST)):\n",
    "    \n",
    "    if(DATA_LIST[idx] == '.DS_Store'):\n",
    "        continue\n",
    "    else:\n",
    "        eopatch = EOPatch.load(os.path.join('./aFractionIndices1_05/interpolation-8days', DATA_LIST[idx]))\n",
    "\n",
    "        features_arr = eopatch.data['FEATURES'].copy()\n",
    "        lpis_data_arr = eopatch.mask_timeless['LPIS_sifra'].copy()\n",
    "        pid_data_arr = eopatch.mask_timeless['PID'].copy()\n",
    "\n",
    "\n",
    "        num_of_days = features_arr.shape[0]\n",
    "        num_of_cells = features_arr.shape[1]\n",
    "        num_of_features = features_arr.shape[3]\n",
    "\n",
    "        for k in range(0, num_of_cells):\n",
    "\n",
    "            tmp_arr = np.zeros((34,7))\n",
    "\n",
    "            for i in range(0, num_of_days):\n",
    "                for j in range(0, num_of_features):\n",
    "                    tmp_arr[i][j] = features_arr[i][k][0][j]\n",
    "\n",
    "            list_of_cells.append(tmp_arr)\n",
    "\n",
    "            tupl = (lpis_data_arr[k][0][0], pid_data_arr[k][0][0])\n",
    "            list_of_groundtruth.append(tupl)\n",
    "            list_of_all_LPIS_data.append([lpis_data_arr[k][0][0]])\n",
    "\n",
    "print(len(list_of_cells), list_of_cells[0].shape)\n",
    "print(len(list_of_groundtruth))\n",
    "print(len(list_of_all_LPIS_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./testni_input_file.npy', list_of_cells)\n",
    "np.save('./ground_truth_file.npy', list_of_groundtruth)\n",
    "# np.save('./LPIS_ground_truth.npy', LPIS_GT_popravljeno)\n",
    "np.save('./LPIS_ground_truth.npy', list_of_all_LPIS_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('./testni_input_file.npy')\n",
    "loaded_gt = np.load('./ground_truth_file.npy')\n",
    "loaded_LPIS_gt = np.load('./LPIS_ground_truth.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Image\n",
    "\n",
    "im = Image.open()\n",
    "im.thumbnail(size, Image.ANTIALIAS)\n",
    "im.save(outfile, \"JPEG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
